{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-Up\n",
    "\n",
    "Start by running the usual Library Import cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load URLs from CSV\n",
    "\n",
    "Run the following line to download the `urls.csv` file to your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    77  100    77    0     0     83      0 --:--:-- --:--:-- --:--:--    84\n"
     ]
    }
   ],
   "source": [
    "!curl https://wagon-public-datasets.s3.amazonaws.com/02-Data-Toolkit/02-Data-Sourcing/urls.csv > urls.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load this CSV in a `urls_df` dataframe using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "urls_df = pd.read_csv('urls.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich Dataset with an API\n",
    "\n",
    "Let's use the `fetch_metadata` function that we just implemented in the `opengraph.py` file.\n",
    "\n",
    "First let's import it and make sure that it works in the Notebook. \n",
    "\n",
    "1. Write the relevant `from ... import ...` line\n",
    "1. Call the `fetch_metadata` on a URL of your choice. You can write `fetch_` then `<TAB>` to autocomplete, then `<SHIFT> + <TAB>` to view the Docstring from your Python file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from opengraph import fetch_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the `urls_df` dataframe to add `title` and `description` columns for each URL\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ†˜ Hint</summary>\n",
    "\n",
    "  <p>Have a look at today's Lecture, you can start by copy/pasting what we did for <code>tracks_df</code> and adapt the code</p>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "urls_df['title'] = \"\"\n",
    "urls_df['description'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in urls_df.iterrows():\n",
    "    meta_data = fetch_metadata (row['url'])\n",
    "    urls_df.loc[index, 'description'] = meta_data['description']\n",
    "    urls_df.loc[index, 'title'] = meta_data['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your code!\n",
    "\n",
    "Run the cell below to check your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /Users/guilhermecavalcantidesabarreto/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/guilhermecavalcantidesabarreto/code/guipyc/data-opengraph_api\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_warmup.py::TestWarmup::test_dataframe_has_new_columns \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.46s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ðŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/warmup.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed warmup step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('warmup',\n",
    "    df_columns=urls_df.columns,\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Autoreload\n",
    "\n",
    "Today's Lecture introduced you to the usefulness of [`autoreload`](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) in the notebook, let's experiment with it!\n",
    "\n",
    "Run the following cell, it should return `True` if your method returns `None` when a website is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_metadata(\"https://www.a.com\") == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open VS Code and change the behavior of the function, to make it return an empty string `\"\"` rather than `None` if the HTTP response is something else than `200`. Save your file on the drive, and re-run the cell above.\n",
    "\n",
    "Do you see something changing? No? That's normal! The first version of the `fetch_metadata` code is stored in the Notebook Kernel.\n",
    "\n",
    "---\n",
    "\n",
    "OK, let's change back the `fetch_metadata` code in VS Code back to `None`.\n",
    "\n",
    "Then, add the following two lines to your first Notebook code cell:\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```\n",
    "\n",
    "Then in the menu bar, go to `Kernel` > `Restart & Run all`.\n",
    "\n",
    "---\n",
    "\n",
    "Now that autoreload is enabled, go to VS Code, and once again change the behavior so that it returns an empty string. Re-run the code cell above. Do you get `False`? Good! That means that the Notebook is now monitoring changes to the files imported, like `opengraph.py`, and will reload them if the code within them changes!\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "You might find this confusing, jumping through Notebook and VS Code, don't worry you will get used to it. The Notebook is a perfect tool to experiment, to keep notes, to get graphical output of the data, etc. Still, the end goal of a Data Team is to **ship** something (a product, an API, a model, etc.), so productizing the code and refactoring it _out_ of the Notebook into proper Python modules is a critical skill that you will learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opengraph import fetch_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function opengraph.fetch_metadata(url)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_metadata('https://www.lewagon.com')\n",
    "fetch_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   Warmup.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   opengraph.py\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add tests/warmup.pickle\n",
    "\n",
    "!git commit -m 'Completed warmup step'\n",
    "\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   Warmup.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   opengraph.py\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add tests/warmup.pickle\n",
    "\n",
    "!git commit -m 'Completed warmup step'\n",
    "\n",
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "9ce94ef8ee190dea0d937bb4ba507385a715f5fe685c1b9c32f6990ad8cb80c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
